---
title: Combining orders from Ball and Express for Spring 2024
author: Daniel R. Williams ^[Director of Quality Control, Greenstreet Growers, Lothian,
  MD] ^[PhD Candidate, Dept. of Ag. & Crop Science, Ohio State University, Columbus,  Ohio]
date: 3 April 2023
updated: 24 June 2024
output:
  pdf_document: default
  html_notebook: default
---

# Abstract


```{r setup, echo=FALSE, error=TRUE, message=TRUE, warning=TRUE, include=FALSE}
# this block loads required packages and some custom functions. 

cran_pacs <- c("tidyverse","writexl","fs","stringr","parallel","multidplyr","foreach","doParallel","generics","withr","rlang","janitor","magrittr","purrr","pwalign","readxl","fuzzyjoin","datawizard")
dev_pacs <- c() #"r-dbi/odbc"
bioc_pacs <- c()
py_pacs <- c()

# install installers
if(length(find.package("pak", quiet = TRUE))==0) install.packages("pak")
if(length(find.package("librarian", quiet = TRUE))==0) pak::pak("librarian")
installer_pacs <- Filter(librarian::check_installed, c(if (length(bioc_pacs) > 0) "BiocManager", if (length(py_pacs) > 0) "reticulate"))
if (length(installer_pacs) > 0) pak::pak(installer_pacs, upgrade = TRUE)

# install and load R pacs
r_pacs <- c(cran_pacs,dev_pacs,bioc_pacs) |> unique()
if (length(r_pacs) > 0) {
  pak::pak(r_pacs, upgrade = FALSE)
  librarian::shelf(r_pacs)
}

# install python packs
if (length(py_pacs)>0) {
  if (!reticulate::py_available(initialize = TRUE)) reticulate::install_python()
  if (reticulate::py_available(initialize = TRUE)) reticulate::py_install(py_pacs)
}

## register cores for foreach
n_cores <- parallel::detectCores()
# registerDoParallel(cores=n_cores)
# stopImplicitCluster()

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
makeCluster(n_cores-1) |> setDefaultCluster()
registerDoParallel(getDefaultCluster())

# dplyr cluster
if(exists("dCluster")) rm(dCluster)
dCluster <- new_cluster(n_cores-1)
cluster_library_quiety <- purrr::quietly(cluster_library)
# cluster_library_quiety(dCluster, loadedNamespaces())
cluster_library_quiety(dCluster, librarian::check_attached())

```

```{r utilityfuns}

## an alignment function for similar names
pairwiseAlightmentMatch = function(x,y) {pwalign::pairwiseAlignment(x,y,scoreOnly = TRUE) > 0}

# name order function. Pulls out words and sorts them. Vectorized.
string_alignment_prep <- function(x) {
  prep_one <- function(y) {
    y |> 
      stringr::str_to_lower() |>
      stringr::str_replace_all("(?<=[:alnum:])[:punct:](?=[:alnum:])"," ") |>
      stringr::str_remove_all("[:punct:]|®|™") |>
      stringr::str_remove_all("(?<=([:space:]|^))(herb)|(he)|(vf)(?=([:space:]|$))") |>
      stringr::str_extract_all("([:alpha:]{2,})|(([:digit:]*(\\.[:digit:]+)?)(?!c$))", simplify = TRUE) |> 
      stringr::str_squish() |> 
      stringr::str_unique() |> 
      as.character() |> 
      stringr::str_sort() |> 
      stringr::str_flatten(collapse = " ")
  }
  sapply(x, prep_one)
}

# this is a two-way name match. Matches are true if the best match x -> y is also the best match y -> x. Vectorized. 
name_match <- function(x,y) {

  x_u <- x |> stringr::str_unique()
  y_u <- y |> stringr::str_unique()
  
  xy_intersect <- generics::intersect(x_u, y_u)
  x_u <- generics::setdiff(x_u,xy_intersect)
  y_u <- generics::setdiff(y_u,xy_intersect)
  
  if((length(x_u) == 0)&(length(y_u) == 0)) {
    out1 <- mapply(\(m,n) {stringr::str_equal(m,n,ignore_case = TRUE)},x,y)
    return(out1)
  }
  
  # print(1)

  doParallel::registerDoParallel(cores=n_cores-1)
  scores <- foreach::foreach(i=1:length(y_u), .combine = rbind, .export = "string_alignment_prep") %dopar% {
    # print("1a")
    raw_score <- pwalign::pairwiseAlignment(x_u |> string_alignment_prep(), y_u[i] |> string_alignment_prep(),scoreOnly = TRUE)
    dplyr::if_else(raw_score>=0,raw_score,-stringr::str_length(paste0(x_u, y_u[i]))/raw_score)
  } |> unlist()
  # print("1b")
  doParallel::stopImplicitCluster()

  # print(2)
  
  y_loc <- apply(scores, 2, which.max) |> unname() |> as.integer()
  x_loc <- apply(scores, 1, which.max) |> unname() |> as.integer()

  x_y_index <- foreach(j=1:length(x_loc), .combine = rbind) %do% c(xname = x_u[x_loc[j]], yname = y_u[j], xi = x_loc[j] |> as.integer(), yi = j |> as.integer())
  y_x_index <- foreach(i=1:length(y_loc), .combine = rbind) %do% c(yname = y_u[y_loc[i]], xname = x_u[i], yi = y_loc[i] |> as.integer(), xi = i |> as.integer())

  # print(3)
  
  joined_index = inner_join(x_y_index |> as_tibble(),y_x_index |> as_tibble()) |>
    mutate(yi = yi |> as.integer(),
           xi = xi |> as.integer(),
           score = scores[yi*xi],
           lmax = pmax(str_length(yname),str_length(xname)),
           lmin = pmin(str_length(yname),str_length(xname)),
           # score_adj = -(lmax)/score,
           score_adj = if_else(score>=0,score,score/(lmax*lmin)))
  
  # TODO ? re-match using the unmatched items from each list. Could also reject matches below a cutoff score.
  
  # print(4)

  out2 <- mapply(\(m,n) {str_equal(m,n,ignore_case = TRUE)|str_equal(joined_index$yname[match(m,joined_index$xname)],n,ignore_case = TRUE)},x,y) |>
    sapply(\(x) {
      if(is.na(x)) FALSE
      else x
      })
  return(out2)
}

# parses file names in a series within a directory to produce an order
order_files <- function(paths, parseFun = identity, baseName = NA) {
  if(length(paths) <= 1) return(paths)
  paths <- paths |> 
    fs::path_file() |>
    fs::path_ext_remove()  
  start <- if(is.na(baseName)) {
    alignment <- pwalign::pairwiseAlignment(paths[2:length(paths)], paths[1])
    alignment@subject@mismatch |> unlist() |> min() 
  } else {
    (baseName |> stringr::str_length()) + 1
  }
  ids <- paths |> stringr::str_sub(start)
  ids |> parseFun() |> 
  base::order()
}

# aligns two strings and returns their matched portion. not working
string_alignment_alike <- Vectorize(function(x,y) {
  # strings <- c(x,y)
  # # strings <- c("Pot 1gal","1g 3pp")
  # sri_order <- strings |> stringr::str_length() |> order(decreasing = TRUE)
  # alignment <- pwalign::pairwiseAlignment(strings[sri_order[1]],strings[sri_order[2]], gapOpening = 10, gapExtension = 4, type = "global")
  # base <- alignment@pattern |> as.character()
  # print(base)
  # print(alignment@pattern@mismatch@unlistData)
  # keepchars <- setdiff(1:str_length(base), alignment@pattern@mismatch@unlistData)
  # print(keepchars)
  # # base |> stringr::str_sub(start = keepchars, end = keepchars) |> stringr::str_flatten() |> stringr::str_squish()
  # strings[sri_order[1]] |> str_sub(start = alignment@pattern@range@start, end = alignment@pattern@range@start + alignment@pattern@range@width -1)
  
  # alignment <- pwalign::pairwiseAlignment(x,y, gapOpening = 10*0, gapExtension = 4*2, type = "global")
  # keepchars <- setdiff(1:str_length(x), alignment@pattern@mismatch@unlistData)
  # # match <- x |> stringr::str_sub(start = keepchars, end = keepchars) |> stringr::str_flatten() |> stringr::str_squish()
  # match <- stringr::str_sub(x, start = alignment@pattern@mismatch@unlistData, end = alignment@pattern@mismatch@unlistData) <- " "
  # match |> stringr::str_flatten() |> stringr::str_squish()
  
  alignment <- pwalign::pairwiseAlignment(x,y, gapOpening = 10*2, gapExtension = 4*1, type = "global")
  match <- alignment@pattern |> as.character() |> str_split_1("")
  keepchars <- setdiff(1:length(match), alignment@pattern@mismatch@unlistData)
  # match[keepchars] |> stringr::str_flatten() |> stringr::str_squish()
  tmp <- character()
  for(i in 1:length(match)) {
    if (i %in% keepchars) tmp[i] <- match[i] else tmp[i] <- " "
  }
  print(tmp)
  tmp |> stringr::str_flatten() |> str_replace_all("[:punct:]"," ") |> stringr::str_squish()
})

# string_alignment_alike(c("plug 288","lin pw 72","Pot 1gal","SD 5K","lin 32lp","32-tray"),c("tray 288","tray 72","point of purchase","pack 5K","tray 32","32 tray"))

```


```{r datasetup, echo=TRUE, error=TRUE, message=FALSE, warning=TRUE, eval=TRUE}
if(is_null(getDefaultCluster())) {
  makeCluster(n_cores-1) |> setDefaultCluster()
  registerDoParallel(getDefaultCluster())
}

plants_dir <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders" |> fs::path_home()
tags_dir <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Tags/" |> fs::path_home()

# e_orders <- plants_dir |> fs::path("Express Seed export","express_open_orders_20240228.xlsx") |>
#   read_xlsx_flex(guess_max = as.integer(.Machine$integer.max/100)) |> 
#   janitor::remove_empty()

# this is a bit excessive, because it really only makes sense to read in the latest open orders file. I've updated to only read the latest open orders file.
e_orders_baseName <- "express_open_orders_"
e_orders_files <- plants_dir |> fs::path("Express Seed export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(e_orders_baseName,".*\\.xlsx"))
e_orders <- foreach::foreach(i=order_files(e_orders_files, baseName = e_orders_baseName, parseFun = ymd) |> max(), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order #", "Purchase Order #", "Customer PO #", "Order Date", "Product #", "Supplier", "QTY Ordered")), .packages = c("readxl")) %dopar% { 
  read_xlsx(e_orders_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`))
  } |> janitor::remove_empty()

# e_delivered <- plants_dir |> fs::path("Express Seed export","express_shipped_orders_20240228.xlsx") |>
#   read_xlsx_flex(guess_max = as.integer(.Machine$integer.max/100)) |> 
#   janitor::remove_empty()

e_delivered_baseName <- "express_shipped_orders_"
e_delivered_files <- plants_dir |> fs::path("Express Seed export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(e_delivered_baseName,".*\\.xlsx"))
e_delivered <- foreach::foreach(i=order_files(e_delivered_files, baseName = e_delivered_baseName, parseFun = ymd), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order #", "Purchase Order #", "Customer PO #", "Order Date", "Product #", "Supplier", "QTY Ordered")), .packages = c("readxl")) %dopar% { 
  read_xlsx(e_delivered_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`))
  } |> janitor::remove_empty()

# join express delivered and ordered by adding rows from e_orders that do not have a key match in e_delivered
# and pull out sizes
e_combined <- e_orders |>
  filter(`Ship Date` > max(e_delivered$`Ship Date`)) |>
  right_join(e_delivered) |>
  mutate(vendor = "Express",
         Size = Description |> str_squish() |> str_extract("(?<=-)[:alnum:]*$"))

b_baseName <- "order_download_"
b_files <- plants_dir |> fs::path("Ball export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(b_baseName,".*\\.xlsx"))
b_orders <- foreach::foreach(i=order_files(b_files, baseName = b_baseName, parseFun = ymd_hms), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order Number", "Order Line")), .packages = c("readxl","stringr")) %dopar% { 
  read_xlsx(b_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    dplyr::mutate(vendor = "Ball",
                 "Order Number" = `Order Number` |> as.character(),
                 "Sales Order Date" = `Sales Order Date` |> lubridate::ymd(),
                 "Ship Date" = `Ship Date` |> lubridate::ymd(),
                 "Total Extended Value" = `Total Extended Value` |> as.numeric(),
                 "Order Line" = `Order Line` |> stringr::str_extract("[:digit:]*"),
                 "Ship Week" = `Ship Week` |> stringr::str_extract("[:digit:]*[:graph:]?[:digit:]*"),
                 "Case Count" = `Case Count` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Unit Price" = `Unit Price` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Royalty" = `Royalty` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Tags" = `Tags` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Freight" = `Freight` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Total Unit Rate" = `Total Unit Rate` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 # "Material Format" = string_alignment_alike(`Size`,`Material Group Description`), ##TODO
                 ) |> 
    dplyr::select(!any_of(c("Not Used1","Not Used2"))) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(`Order Number`))
  } |> janitor::remove_empty() |>
  # unite(col = "Description", any_of(c("Class","Variety")), sep = " ", remove = FALSE)
  rowwise() |>
  mutate("Description" = str_c(`Class`,`Variety`, sep = " "))

mtag_baseName <- "GREENSTREET_GROWERS_INC_Order Export_"
mtag_files <- tags_dir |> fs::path("MasterTag") |> fs::dir_ls() |> fs::path_filter(regex = paste0(mtag_baseName,".*\\.xlsx"))
# registerDoParallel(cores=n_cores-1)
mtag_orders <- foreach::foreach(i=order_files(mtag_files, baseName = mtag_baseName, parseFun = mdy), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("MT Sales Order #", "MT ID")), .packages = c("foreach")) %dopar% { 
  foreach(j=c(2,1), .combine = dplyr::left_join) %dopar% {
    read_xlsx(path = mtag_files[i], sheet = j, guess_max = as.integer(.Machine$integer.max/100))
  } |> janitor::remove_empty("rows") |>
    dplyr::distinct()
  } |> janitor::remove_empty() |>
    dplyr::mutate(vendor = "MasterTag",
                  "Estimated Ship Date" = `Estimated Ship Date` |> mdy() ) #,
                  # "MT Item Description" = `MT Item Description` |> str_remove_all("[:punct:]|®|™") |> str_squish() |> str_to_lower())


# Import from finished product suppliers
# including: Cavanos, George Radebaugh, John Radebaugh, Hillcrest, & Tidal Creek
cavanos_path <- plants_dir |> fs::path("Other Suppliers Invoices", "Cavanos Perennials", "Cavanos Invoices.xlsx")
george_radebaugh_path <- plants_dir |> fs::path("Other Suppliers Invoices", "George Radebaugh", "George Radebaugh Wholesale Growers Invoices.xlsx")
john_radebaugh_path <- plants_dir |> fs::path("Other Suppliers Invoices", "John Radebaugh", "John Radebaugh Greenhouses Invoices.xlsx")
hillcrest_path <- plants_dir |> fs::path("Other Suppliers Invoices", "Hillcrest Nursery", "Hillcrest Nursery Invoices.xlsx")
tidal_creek_path <- plants_dir |> fs::path("Other Suppliers Invoices", "Tidal Creek", "TidalCreekGrowers2023q1.xlsx")

cavanos_data <- cavanos_path |> read_xlsx(col_types = c(rep("text",2),rep("date",2),rep("text",10),rep("numeric",8)))
g_radebaugh_data <- george_radebaugh_path |> read_xlsx(col_types = c(rep("text",2),rep("date",2),rep("text",10),rep("numeric",8)))
j_radebaugh_data <- john_radebaugh_path |> read_xlsx(col_types = c(rep("text",2),rep("date",2),rep("text",10),rep("numeric",8)))
hillcrest_data <- hillcrest_path |> read_xlsx(col_types = c(rep("text",2),rep("date",2),rep("text",9),rep("numeric",7)))
tidal_creek_data <- tidal_creek_path |> read_xlsx(col_types = c("text", "text", "date", "date", rep("text",8), rep("numeric",5)))

finished_product_data <- full_join(cavanos_data, g_radebaugh_data) |> 
  full_join(j_radebaugh_data) |>
  full_join(hillcrest_data) |>
  full_join(tidal_creek_data) |>
  mutate(type = "finished",
         across(where(is.character),str_squish),
         `ship week` = str_c(`ship date` |> year(), `ship date` |> isoweek()))


```

```{r singlefileimport, eval=FALSE}

e_orders <- tibble()

e_orders_file <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders/2024/Pansy&Kale 2024" |> fs::path_home() |> fs::path("express_shipped_orders_fall_2023.xlsx")

e_delivered <- read_xlsx_flex(e_orders_file, guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`)) |> 
  janitor::remove_empty()


b_file <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders/2024/Pansy&Kale 2024" |> fs::path_home() |> fs::path("Ball order_download_20240624075842.xlsx")

b_orders <- read_xlsx_flex(b_file, guess_max = as.integer(.Machine$integer.max/100)) |>
    dplyr::mutate(vendor = "Ball",
                 "Order Number" = `Order Number` |> as.character(),
                 "Sales Order Date" = `Sales Order Date` |> lubridate::ymd(),
                 "Ship Date" = `Ship Date` |> lubridate::ymd(),
                 "Total Extended Value" = `Total Extended Value` |> as.numeric(),
                 "Order Line" = `Order Line` |> stringr::str_extract("[:digit:]*"),
                 "Ship Week" = `Ship Week` |> stringr::str_extract("[:digit:]*[:graph:]?[:digit:]*"),
                 "Case Count" = `Case Count` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Unit Price" = `Unit Price` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Royalty" = `Royalty` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Tags" = `Tags` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Freight" = `Freight` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Total Unit Rate" = `Total Unit Rate` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*")) |> 
    dplyr::select(!any_of(c("Not Used1","Not Used2"))) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(`Order Number`)) |> 
  janitor::remove_empty() |>
  unite(col = "Description", any_of(c("Class","Variety")), sep = " ", remove = FALSE)


## special filters
start_date <- "08-01-2023" |> mdy() |> as.POSIXct() |> as_date() |> is.Date()
end_date <- "10-31-2023" |> mdy()

e_delivered <- e_delivered |>
  mutate(across(where(is.POSIXct),as_date)) |>
  filter(`Ship Date` >= start_date,
         `Ship Date` <= end_date)

b_orders <- b_orders |> 
  mutate(across(where(is.Date),as_date)) |>
  filter(`Ship Date` >= start_date,
         `Ship Date` <= end_date)


```

```{r import_odbc, eval=FALSE}

odbc::odbcListDataSources() |> tail(1) |> select(1) |> unlist()

odbc::odbcListDrivers()

con <- DBI::dbConnect(drv = odbc::odbc(), dsn = odbc::odbcListDataSources() |> tail(1) |> select(1) |> unlist())



```


```{r e_b_join}

if(is_null(getDefaultCluster())) {
  makeCluster(n_cores-1) |> setDefaultCluster()
  registerDoParallel(getDefaultCluster())
}

# need a function for extracting and alighning the plug tray sizes (etc)
e_combined$Size |> unique()
b_orders$Size |> unique()


alignment <- c("vendor" = "vendor", 
               "Order #" = "Order Number",
               "Customer PO #" = "PO Number", 
               "Order Date" = "Sales Order Date", 
               "Ship Date" = "Ship Date", 
               "Week" = "Ship Week", 
               "Product #" = "Ball Material Number", 
               "Description" = "Description", 
               "Supplier" = "Supplier", 
               "QTY Ordered" = "Quantity", 
               "Total" = "Total Extended Value",
               "Size" = "Size")

b_keep_cols <- alignment |> unname() |> c("Reference Number") |> unique()

plants_joined <- full_join(e_combined, b_orders, by=alignment) |>
  select(names(alignment)) |>
  mutate(across(where(is.character),str_squish)) |>
  # partition(dCluster) |>
  mutate(type = case_when(
    Size |> str_detect(regex("[:digit:]{2}C", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("[:digit:]{3}C", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("[:digit:]{3}SS", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("((lin)|(split)|(plug)|(cust((pl)|(ln))?)|(b?kit)|(pu?nch))([:space:]PW)?[:space:]+[:digit:]{2}[:digit:]?", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("Oasis[:space:]+WD", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("Pull[:space:]+Pack", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("^21$", ignore_case = T)) ~ "plug",
    Size |> str_detect(regex("(MPL)|([:digit:]+[KHM])", ignore_case = T)) ~ "seed",
    Size |> str_detect(regex("(URC)|(callus)|(unrooted)|(Pre[:space:]+Intr)", ignore_case = T)) ~ "urc",
    Size |> str_detect(regex("(brt)|(bareroot)|(BB[:space:]+[:alnum:]+)", ignore_case = T)) ~ "bareroot",
    Size |> str_detect(regex("(Kit 8\")", ignore_case = T)) ~ "bareroot",
    Size |> str_detect(regex("Dor[:digit:][:space:]+[:digit:]\\+C", ignore_case = T)) ~ "bareroot",
    Size |> str_detect(regex("TAG", ignore_case = T)) ~ "tag",
    Size |> str_detect(regex("pot", ignore_case = T)) ~ "pot",
    Size |> str_detect(regex("tray", ignore_case = T)) ~ "tray",
    Size |> str_detect(regex("(tower)|(74[:space:]+L(CF)|(FC))", ignore_case = T)) ~ "media",
    Size |> str_detect(regex("(4.7[:space:]+Gal)|(5[:space:]+Pounds)", ignore_case = T)) ~ "fertilizer",
    Size |> str_detect(regex("AM[:space:]+[:digit:]\\.?[:digit:]?[:space:]+ft", ignore_case = T)) ~ "lighting",
    Size |> str_detect(regex("(2.2S)|(le)", ignore_case = T)) ~ "lighting",
    Size |> str_detect(regex("fnsh", ignore_case = T)) ~ "finished",
    Size |> str_detect(regex("(bench)|(sign)|(banner)", ignore_case = T)) ~ "signage",
    .default = Size |> str_squish() |> as.character()
  )) ##|>
    # collect()
  ## |>
  # rowwise() |>
  # mutate(Description = Description |> str_to_lower() |> str_extract_all("([:alpha:]{2,})|([:digit:]*(\\.[:digit:]+)(?!C$))", simplify = TRUE) |> str_squish() |> unique() |> as.character() |> str_flatten(collapse = " "))

# checking what isn't categorized yet
# plants_joined |>
#   group_by(type) |>
#   summarise(lines = n(), qty = sum(`QTY Ordered`)) |>
#   arrange(desc(qty))
# 
# plants_joined |>
#   filter(type |> is.na())

```

```{r plant_names_classifications}
# edit 20241113 much faster now. moved all code to generate table into an external script. Loading externally much faster than reading in as text here.

plant_reference_list_path <- plants_dir |> fs::path("supplementary data","plant_reference_list.csv")

if (fs::file_exists(plant_reference_list_path)) {
  plant_classifications <- plant_reference_list_path |> read_csv()
  } else {
    source(plants_dir |> fs::path("supplementary data","plant_reference_list_generator.R"))
    plant_classifications |> write_csv(plant_reference_list_path)
}

```


```{r filter, eval=TRUE}

## 

if(!exists("dCluster")) {
  dCluster <- new_cluster(n_cores-1)
  cluster_library_quiety <- purrr::quietly(cluster_library)
  cluster_library_quiety(dCluster, librarian::check_attached())
}



plants_classified <- plants_joined |>
  # partition(dCluster) |>
  dplyr::mutate(Department = if_else(Description |> str_to_lower() |> str_detect("(^|[:space:])(he)|(vf)|(herb)[:space:]"), "edibles",NA),
                Description = Description |> str_remove_all("(?<=([:space:]|^))(([Hh][Ee][Rr][Bb])|([Hh][Ee])|([Vv][Ff]))(?=([:space:]|$))") |> str_squish()) |>
  fuzzy_left_join(plant_classifications, by = c("Description" = "common name"), \(x,y) {
    str_detect(str_to_lower(x),str_c("(^|[:space:])",str_to_lower(y),"(((es)|s)?($|[:space:]))"))
    }) #|>
  # collect()
## TO VIEW WHAT ISN'T CAPTURED IN ASSIGNMENTS
# plants_classified |>
#   filter(dept |> is.na()) |>
#   view()

plants_filtered <- plants_classified |>
  partition(dCluster) |>
  dplyr::filter(str_equal(type,"plug") | str_equal(type,"finished"),
                (`Ship Date` >= "20231101" |> ymd())&(`Ship Date` < "20241101" |> ymd()),
                (str_detect(dept,"edible")),
                !is.na(dept)) |> # |str_detect(Department,"edible")))|>
                # Supplier |> str_equal("Kube Pak"),
                # (Description |> str_detect("(^|[:space:])(HE)|(VF)[:space:]"))|(`Customer PO #` |> str_to_lower() |> str_detect("(herb)|(veg)"))) |>
  # dplyr::mutate(Description = Description |> str_remove_all("(?<=([:space:]|^))((herb)|(he)|(vf))(?=([:space:]|$))") |> str_squish()) |>
  collect()

finished_product_filtered <- finished_product_data |>
  mutate(`ship date` = if_else(!is.na(`ship date`),`ship date`, `invoice date`)) |>
  fuzzy_left_join(plant_classifications, by = c("Item Description" = "common name"), \(x,y) {
    str_detect(str_to_lower(x),str_c("(^|[:space:])",str_to_lower(y),"(((es)|s)?($|[:space:]))"))
    }) |>
  partition(dCluster) |>
  dplyr::filter(str_equal(type,"plug") | str_equal(type,"finished"),
                (`ship date` >= "20231101" |> ymd())&(`ship date` < "20241101" |> ymd()),
                (str_detect(dept,"edible")),
                !is.na(dept))|>
  collect()


## There might be a duplication issue when merging with the plant_classifications table. But it might have applied only to previous version. I haven't checked. 20241125
# FIX THIS TODO??
plugs_and_finished_filtered <- full_join(plants_filtered, finished_product_filtered, by = join_by("Ship Date" == "ship date",
                                                                                                  "Description" == "Item Description",
                                                                                                  "Size" == "size",
                                                                                                  "QTY Ordered" == "units",
                                                                                                  "type",
                                                                                                  "vendor",
                                                                                                  "Supplier",
                                                                                                  "dept", 
                                                                                                  "subdept",
                                                                                                  "genus", 
                                                                                                  "common name",
                                                                                                  "Order #" == "invoice number",
                                                                                                  "Order Date" == "invoice date",
                                                                                                  "Week" == "ship week",
                                                                                                  "Customer PO #" == "Customer PO Number",
                                                                                                  "Product #" == "SKU",
                                                                                                  "Total" == "net extended price"))








tags_filtered <- mtag_orders |>
  dplyr::filter((`Estimated Ship Date` >= "20231101" |> ymd())&(`Estimated Ship Date` < "20241101" |> ymd()),
                str_detect(`PO #` |> str_to_lower(),"(herb)|(veg)|(daniel)"))

```

```{r mtag_join, eval = F}


plants_prep <- plants_filtered |>
  summarise(`QTY Ordered` = sum(`QTY Ordered`), .by = any_of(c("Description"))) |>
  rename_with(\(x) paste0("plants_",x))

tags_prep <- tags_filtered |>
  summarise(`Ordered Quantity` = sum(`Ordered Quantity`), .by = any_of(c("MT Item Description"))) |>
  rename_with(\(x) paste0("tags_",x))

aligned <- fuzzyjoin::fuzzy_full_join(plants_prep, tags_prep, by=c("plants_Description"="tags_MT Item Description"), match_fun = name_match)
## adding tag counts
aligned %<>%
  mutate(subdept = case_when(plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(he(rb)?)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(vf)(?=($|[:space:]))") ~ "veg",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(lavandula)|(lavender)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(eucalyptus)|(lemon[:space:]?bush)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(marigold)(?=($|[:space:]))") ~ "veg",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(melampodium)(?=($|[:space:]))") ~ "veg",
                             .default = NA),
         tags_per_plug = case_match(subdept,
                                    c("herb") ~ 1,
                                    c("veg") ~ 4,
                                    .default = 1),
         tags_need = `plants_QTY Ordered` / tags_per_plug,
         tags_deficit = (tags_need - datawizard::convert_na_to(`tags_Ordered Quantity`,replacement = 0)) |> pmax(0))

# can i use dplyr::join with dplyr::closest() with pairwiseAligment scores? or maybe need to use fuzzyjoin


```


```{r export, eval=TRUE}
# plants_joined %<>%
  # mutate(size = case_when(str_detect(`Customer PO #`,"(^4.5)|(4.5[:space:]?((IN)|(in)|(\")))") ~ "4.5 in",
  #                          str_detect(`Customer PO #`,"^804") ~ "804",
  #                          str_detect(`Customer PO #`,"(^10)|(10[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "10 in hb",
  #                          str_detect(`Customer PO #`,"(^8)|(8[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "8 in hb",
  #                          str_detect(`Customer PO #`,"(^12)|(12[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "12 in hb",
  #                          str_detect(`Customer PO #`,"(^11)|(11[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "11 in hb",
  #                          str_detect(`Customer PO #`,"(^14)|(14[:space:]?((IN)|(in)|(\")))")  ~ "14 in",
  #                          str_detect(`Customer PO #`,"(^4)|(4[:space:]?((IN)|(in)|(\")))")  ~ "4 in",
  #                          str_detect(`Customer PO #`,"(^6)|(6[:space:]?((IN)|(in)|(\")))")  ~ "6 in",
  #                          str_detect(`Customer PO #`,"(^12)|(12[:space:]?((IN)|(in)|(\")))")  ~ "12 in",
  #                          str_detect(`Customer PO #`,"(^11)|(11[:space:]?((IN)|(in)|(\")))")  ~ "11 in",
  #                          str_detect(`Customer PO #`,"(^10)|(10[:space:]?((IN)|(in)|(\")))")  ~ "10 in",
  #                          str_detect(`Customer PO #`,"1[:space:]?((GAL)|(G[:space:])|(G$))")  ~ "1 gal",
  #                          str_detect(`Customer PO #`,"((HB)|(BSKT)|(BASKET))")  ~ "10 in hb",
  #                          str_detect(`Customer PO #`,"^(liner)|(LINER)")  ~ "liner",
  #                          str_detect(`Customer PO #`,"^PW")  ~ "PW",
  #                          .default = "other"))

plugs_and_finished_filtered |>
  mutate(`common name` = `common name` |> str_remove_all("[\\?\\^]")) |>
  write_xlsx(path = plants_dir |> fs::path("2025", "2024_edibles_v0.31.xlsx"))
```

```{r averages, eval=FALSE}

plugs_tbl <- tibble_row(size = "4 in", plugs = 1) |> # .25
  tibble::add_case(size = "4.5 in", plugs = 1)|> # .07
  tibble::add_case(size = "6 in", plugs = 3)|> # .124
  tibble::add_case(size = "10 in hb", plugs = 5)|> # .079
  tibble::add_case(size = "11 in hb", plugs = 6)|> # .069
  tibble::add_case(size = "8 in hb", plugs = 4)|> # .09
  tibble::add_case(size = "14 in", plugs = 3)|>
  tibble::add_case(size = "1 gal", plugs = 1)|>
  tibble::add_case(size = "liner", plugs = 1)|>
  tibble::add_case(size = "PW", plugs = 1)|>
  tibble::add_case(size = "12 in hb", plugs = 7)|>
  tibble::add_case(size = "12 in", plugs = 7)|>
  tibble::add_case(size = "10 in", plugs = 5)|>
  tibble::add_case(size = "804", plugs = 1)

averages <- plants_joined |>
  dplyr::filter(`Ship Date` >= ymd("2024-01-01")) |>
  dplyr::mutate(category = if_else(str_detect(Supplier |> str_to_lower(), "four[:space:]?star"), "PW", "") |> str_c(size, sep = " ")) |>
  dplyr::summarise(dplyr::across(c("QTY Ordered","Total"),sum), .by = dplyr::any_of(c("category", "size"))) |>
  dplyr::left_join(plugs_tbl) |>
  dplyr::mutate(plug_avg_cost = Total / `QTY Ordered`,
                pot_avg_cost = plug_avg_cost * plugs) |>
  dplyr::filter(!is.na(pot_avg_cost)) |>
  select(1,3,4,6,7) |>
  dplyr::arrange(category,desc(`QTY Ordered`))

```


```{r terminateClusters, eval=FALSE}
# dplyr cluster
if(exists("dCluster")) rm(dCluster)

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
```