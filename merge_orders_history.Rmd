---
title: Combining orders from Ball and Express for Spring 2024
author: Daniel R. Williams ^[Director of Quality Control, Greenstreet Growers, Lothian,
  MD] ^[PhD Candidate, Dept. of Ag. & Crop Science, Ohio State University, Columbus,  Ohio]
date: 3 April 2023
updated: 24 June 2024
output:
  pdf_document: default
  html_notebook: default
---

# Abstract


```{r setup, echo=FALSE, error=TRUE, message=TRUE, warning=TRUE, include=FALSE}
# this block loads required packages and some custom functions. 

cran_pacs <- c("tidyverse","writexl","fs","stringr","parallel","multidplyr","foreach","doParallel","generics","withr","rlang","janitor","magrittr","purrr","pwalign")
dev_pacs <- c("r-dbi/odbc") 
bioc_pacs <- c()
py_pacs <- c()

# install installers
if(!nzchar(find.package("pak", quiet = TRUE))) install.packages("pak")
installer_pacs <- c(if (length(bioc_pacs) > 0) "BiocManager",
                    if (length(py_pacs) > 0) "reticulate")
if (length(installer_pacs) > 0) pak::pak(installer_pacs, upgrade = TRUE)

# install and load R pacs
r_pacs <- c(cran_pacs,dev_pacs,bioc_pacs)
if (length(r_pacs) > 0) {
  r_pacs <- c("librarian",r_pacs) |> 
    c(if (length(bioc_pacs) > 0) "BiocManager") |>
    c(if (length(py_pacs) > 0) "reticulate") |> 
    unique()
  pak::pak(r_pacs, upgrade = TRUE)
  librarian::shelf(r_pacs)
}

# install python packs
if (length(py_pacs)>0) {
  # if (!nzchar(find.package("reticulate", quiet = TRUE))) install.packages("reticulate", quiet = TRUE)
  if (!reticulate::py_available(initialize = TRUE)) reticulate::install_python()
  if (reticulate::py_available(initialize = TRUE)) reticulate::py_install(py_pacs)
}

# cran_pacs <- c("rlang", "pkgbuild","librarian", "pak", "rmarkdown", "tidyselect", "tidyverse", "magrittr", "stats", "measurements", "knitr", "foreach", "doParallel", "parallel", "fs", "janitor", "stringr", "readxl", "writexl","fuzzyjoin", "chromote", "pdftools", "lubridate", "readr", "tidyr", "forcats", "purrr", "stringdist", "multidplyr") |> unique() # "rvest", "polite", "XML", "tabulizer", "gt", "bigmemory", "odbc"
# dev_pacs <- c("r-dbi/odbc") ## "aperium/rutil")
# bioc_pacs <- c("Biostrings", "pwalign") #,"msa")
# py_pacs <- c("camelot-py")
# 
# UPDATE <- FALSE
# QUIET <- FALSE
# ASK <- FALSE
# 
# # packlist <- c(cran_pacs, bioc_pacs, dev_pacs) 
# # for (x in packlist) {packlist |> sapply(\(x) try(unloadNamespace(x)))}
# # loadedNamespaces()
# 
# ## function to quietly find list of packages
# find_package_quiet <- function(pkgs, ...) unlist(find.package(pkgs, quiet = QUIET, ...))
# install_as_needed <- function(pacs, inst_fun = install.packages, check_fun = find_package_quiet, ...) {
#   inst_fun(setdiff(pacs,names(unlist(sapply(pacs,\(x) check_fun(x))))),...)
# }
# 
# # install cran packs
# if (length(cran_pacs) > 0) install_as_needed(cran_pacs,install.packages, quiet = QUIET)
# 
# # install github dev packs
# if (length(dev_pacs)>0) {
#   if (!requireNamespace("pak", quietly = QUIET)[]) install.packages("pak", quiet = QUIET)
#   install_as_needed(dev_pacs,pak::pak, ask = ASK, upgrade = UPDATE)
# }
# 
# # install bioc packs
# if (length(bioc_pacs)>0) {
#   if (!requireNamespace("BiocManager", quietly = QUIET)[]) install.packages("BiocManager", quiet = QUIET)
#   require(BiocManager)
#   BiocManager::install(version = "3.19", update = UPDATE, ask=ASK)
#   # install_as_needed(bioc_pacs,inst_fun = BiocManager::install, update = UPDATE, ask=ASK)
#   BiocManager::install(bioc_pacs, update = UPDATE, ask=ASK)
# }
# 
# if (!requireNamespace("librarian", quietly = QUIET)[]) install.packages("librarian", quiet = QUIET)
# if (!requireNamespace("pak", quietly = QUIET)[]) install.packages("pak", quiet = QUIET)
# librarian::shelf(cran_pacs, bioc_pacs, dev_pacs, quiet = QUIET)
# installed_req_pkgs <- pak::pkg_status(c(cran_pacs, bioc_pacs, dev_pacs))$package
# # make sure everything is loaded
# installed_req_pkgs |> sapply(requireNamespace, character.only = TRUE, quietly = QUIET)
# loaded_pacs <- search() |> stringr::str_extract("(?<=:).*$") |> na.omit()
# 
# # install python packs
# if (length(py_pacs)>0) {
#   if (!requireNamespace("reticulate", quietly = QUIET)[]) install.packages("reticulate", quiet = QUIET)
#   if (!reticulate::py_available(initialize = TRUE)) reticulate::install_python()
#   if (reticulate::py_available(initialize = TRUE)) reticulate::py_install(py_pacs)
# }

## register cores for foreach
n_cores <- parallel::detectCores()
# registerDoParallel(cores=n_cores)
# stopImplicitCluster()

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
makeCluster(n_cores-1) |> setDefaultCluster()
registerDoParallel(getDefaultCluster())

# dplyr cluster
if(exists("dCluster")) rm(dCluster)
dCluster <- new_cluster(n_cores-1)
cluster_library_quiety <- purrr::quietly(cluster_library)
# cluster_library_quiety(dCluster, loadedNamespaces())
cluster_library_quiety(dCluster, check_attached())

```

```{r xlxs_function, echo=FALSE, error=TRUE, message=TRUE, warning=TRUE, include=FALSE}
# These are some sloppy workarounds for reading and writing data from and to excel files. Some of the readxl and writexl are preferred but they are not universally supported. If they are not installed, these functions use on of the other two packages for xlsx-file handling in the order of preference (openxlsx is preferred over xlsx). For simplicity and robustness many features of the packages are not accessible except where they can be translated 1-to-1 across all three. Ideally, The resulting data should be approximately identical in structure, datatypes, and column names regardless of the function it is using to read or write data.

read_xlsx_flex <- function(path, sheet = NULL, range = NULL, col_names = TRUE, ...) {
  if(nzchar(find.package("readxl"))) use_which <- "readxl"
  else if (nzchar(find.package("openxlsx"))) use_which <- "openxlsx"
  else if (nzchar(find.package("xlsx"))) use_which <- "xlsx"
  else return("please install one of: readxl, openxlsx, xlsx")
  #
  sheet_index <- switch (typeof(sheet),
    "NULL" = 1,
    "double" = sheet,
    "integer" = sheet,
    "numeric" = sheet,
    "character" = NULL
  )
  sheet_name <- switch (typeof(sheet),
    "NULL" = NULL,
    "double" = NULL,
    "integer" = NULL,
    "numeric" = NULL,
    "character" = sheet
  )
  # use_which <- "readxl"
  switch (use_which,
    "readxl" = readxl::read_xlsx(path = path, sheet = sheet, range = range, col_names = col_names, ...),
    "openxlsx" = openxlsx::read.xlsx(xlsxFile = path, sheet = ifelse(!is_null(sheet_index), sheet_index, 1) , colNames = col_names, check.names = FALSE, sep.names = " ", ...),
    "xlsx" = xlsx::read.xlsx(file = path, sheetIndex = sheet_index, sheetName = sheet_name, header = col_names, as.data.frame=TRUE, check.names = FALSE, ...)
  )
}


write_xlsx_flex <- function(x, path = tempfile(fileext = ".xlsx")) {
  if(nzchar(find.package("writexl"))) use_which <- "writexl"
  else if (nzchar(find.package("openxlsx"))) use_which <- "openxlsx"
  else if (nzchar(find.package("xlsx"))) use_which <- "xlsx"
  else return("please install one of: writexl, openxlsx, xlsx")
  # use_which <- "xlsx"
  switch (use_which,
    "writexl" = writexl::write_xlsx(x = x, path = path, col_names = TRUE),
    "openxlsx" = openxlsx::write.xlsx(x = x, file = path, asTable = TRUE, overwrite = TRUE),
    "xlsx" = xlsx::write.xlsx2(x = as.data.frame(x), file = path, row.names = FALSE, showNA = FALSE) # puts the rownames in column A. removing them throws bugs.
  )
}

```

```{r utilityfuns}

## an alignment function for similar names
pairwiseAlightmentMatch = function(x,y) {pwalign::pairwiseAlignment(x,y,scoreOnly = TRUE) > 0}

# name order function. Pulls out words and sorts them. Vectorized.
string_alignment_prep <- function(x) {
  prep_one <- function(y) {
    y |> 
      stringr::str_to_lower() |>
      stringr::str_replace_all("(?<=[:alnum:])[:punct:](?=[:alnum:])"," ") |>
      stringr::str_remove_all("[:punct:]|®|™") |>
      stringr::str_remove_all("(?<=([:space:]|^))(herb)|(he)|(vf)(?=([:space:]|$))") |>
      stringr::str_extract_all("([:alpha:]{2,})|(([:digit:]*(\\.[:digit:]+)?)(?!c$))", simplify = TRUE) |> 
      stringr::str_squish() |> 
      stringr::str_unique() |> 
      as.character() |> 
      stringr::str_sort() |> 
      stringr::str_flatten(collapse = " ")
  }
  sapply(x, prep_one)
}

# this is a two-way name match. Matches are true if the best match x -> y is also the best match y -> x. Vectorized. 
name_match <- function(x,y) {

  x_u <- x |> stringr::str_unique()
  y_u <- y |> stringr::str_unique()
  
  xy_intersect <- generics::intersect(x_u, y_u)
  x_u <- generics::setdiff(x_u,xy_intersect)
  y_u <- generics::setdiff(y_u,xy_intersect)
  
  if((length(x_u) == 0)&(length(y_u) == 0)) {
    out1 <- mapply(\(m,n) {stringr::str_equal(m,n,ignore_case = TRUE)},x,y)
    return(out1)
  }
  
  # print(1)

  doParallel::registerDoParallel(cores=n_cores-1)
  scores <- foreach::foreach(i=1:length(y_u), .combine = rbind, .export = "string_alignment_prep") %dopar% {
    # print("1a")
    raw_score <- pwalign::pairwiseAlignment(x_u |> string_alignment_prep(), y_u[i] |> string_alignment_prep(),scoreOnly = TRUE)
    dplyr::if_else(raw_score>=0,raw_score,-stringr::str_length(paste0(x_u, y_u[i]))/raw_score)
  } |> unlist()
  # print("1b")
  doParallel::stopImplicitCluster()

  # print(2)
  
  y_loc <- apply(scores, 2, which.max) |> unname() |> as.integer()
  x_loc <- apply(scores, 1, which.max) |> unname() |> as.integer()

  x_y_index <- foreach(j=1:length(x_loc), .combine = rbind) %do% c(xname = x_u[x_loc[j]], yname = y_u[j], xi = x_loc[j] |> as.integer(), yi = j |> as.integer())
  y_x_index <- foreach(i=1:length(y_loc), .combine = rbind) %do% c(yname = y_u[y_loc[i]], xname = x_u[i], yi = y_loc[i] |> as.integer(), xi = i |> as.integer())

  # print(3)
  
  joined_index = inner_join(x_y_index |> as_tibble(),y_x_index |> as_tibble()) |>
    mutate(yi = yi |> as.integer(),
           xi = xi |> as.integer(),
           score = scores[yi*xi],
           lmax = pmax(str_length(yname),str_length(xname)),
           lmin = pmin(str_length(yname),str_length(xname)),
           # score_adj = -(lmax)/score,
           score_adj = if_else(score>=0,score,score/(lmax*lmin)))
  
  # TODO ? re-match using the unmatched items from each list. Could also reject matches below a cutoff score.
  
  # print(4)

  out2 <- mapply(\(m,n) {str_equal(m,n,ignore_case = TRUE)|str_equal(joined_index$yname[match(m,joined_index$xname)],n,ignore_case = TRUE)},x,y) |>
    sapply(\(x) {
      if(is.na(x)) FALSE
      else x
      })
  return(out2)
}

# parses file names in a series within a directory to produce an order
order_files <- function(paths, parseFun = identity, baseName = NA) {
  if(length(paths) <= 1) return(paths)
  paths <- paths |> 
    fs::path_file() |>
    fs::path_ext_remove()  
  start <- if(is.na(baseName)) {
    alignment <- pwalign::pairwiseAlignment(paths[2:length(paths)], paths[1])
    alignment@subject@mismatch |> unlist() |> min() 
  } else {
    (baseName |> stringr::str_length()) + 1
  }
  ids <- paths |> stringr::str_sub(start)
  ids |> parseFun() |> 
  base::order()
}

# aligns two strings and returns their matched portion. not working
string_alignment_alike <- Vectorize(function(x,y) {
  # strings <- c(x,y)
  # # strings <- c("Pot 1gal","1g 3pp")
  # sri_order <- strings |> stringr::str_length() |> order(decreasing = TRUE)
  # alignment <- pwalign::pairwiseAlignment(strings[sri_order[1]],strings[sri_order[2]], gapOpening = 10, gapExtension = 4, type = "global")
  # base <- alignment@pattern |> as.character()
  # print(base)
  # print(alignment@pattern@mismatch@unlistData)
  # keepchars <- setdiff(1:str_length(base), alignment@pattern@mismatch@unlistData)
  # print(keepchars)
  # # base |> stringr::str_sub(start = keepchars, end = keepchars) |> stringr::str_flatten() |> stringr::str_squish()
  # strings[sri_order[1]] |> str_sub(start = alignment@pattern@range@start, end = alignment@pattern@range@start + alignment@pattern@range@width -1)
  
  # alignment <- pwalign::pairwiseAlignment(x,y, gapOpening = 10*0, gapExtension = 4*2, type = "global")
  # keepchars <- setdiff(1:str_length(x), alignment@pattern@mismatch@unlistData)
  # # match <- x |> stringr::str_sub(start = keepchars, end = keepchars) |> stringr::str_flatten() |> stringr::str_squish()
  # match <- stringr::str_sub(x, start = alignment@pattern@mismatch@unlistData, end = alignment@pattern@mismatch@unlistData) <- " "
  # match |> stringr::str_flatten() |> stringr::str_squish()
  
  alignment <- pwalign::pairwiseAlignment(x,y, gapOpening = 10*2, gapExtension = 4*1, type = "global")
  match <- alignment@pattern |> as.character() |> str_split_1("")
  keepchars <- setdiff(1:length(match), alignment@pattern@mismatch@unlistData)
  # match[keepchars] |> stringr::str_flatten() |> stringr::str_squish()
  tmp <- character()
  for(i in 1:length(match)) {
    if (i %in% keepchars) tmp[i] <- match[i] else tmp[i] <- " "
  }
  print(tmp)
  tmp |> stringr::str_flatten() |> str_replace_all("[:punct:]"," ") |> stringr::str_squish()
})

# string_alignment_alike(c("plug 288","lin pw 72","Pot 1gal","SD 5K","lin 32lp","32-tray"),c("tray 288","tray 72","point of purchase","pack 5K","tray 32","32 tray"))

```


```{r datasetup, echo=TRUE, error=TRUE, message=FALSE, warning=TRUE, eval=TRUE}
# skipping for single-file reading

if(is_null(getDefaultCluster())) {
  makeCluster(n_cores-1) |> setDefaultCluster()
  registerDoParallel(getDefaultCluster())
}

plants_dir <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders" |> fs::path_home()
tags_dir <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Tags/" |> fs::path_home()

# e_orders <- plants_dir |> fs::path("Express Seed export","express_open_orders_20240228.xlsx") |>
#   read_xlsx_flex(guess_max = as.integer(.Machine$integer.max/100)) |> 
#   janitor::remove_empty()

# this is a bit excessive, because it really only makes sense to read in the latest open orders file. I've updated to only read the latest open orders file.
e_orders_baseName <- "express_open_orders_"
e_orders_files <- plants_dir |> fs::path("Express Seed export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(e_orders_baseName,".*\\.xlsx"))
e_orders <- foreach::foreach(i=order_files(e_orders_files, baseName = e_orders_baseName, parseFun = ymd) |> max(), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order #", "Purchase Order #", "Customer PO #", "Order Date", "Product #", "Supplier", "QTY Ordered")), .packages = c("readxl")) %dopar% { 
  read_xlsx(e_orders_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`))
  } |> janitor::remove_empty()

# e_delivered <- plants_dir |> fs::path("Express Seed export","express_shipped_orders_20240228.xlsx") |>
#   read_xlsx_flex(guess_max = as.integer(.Machine$integer.max/100)) |> 
#   janitor::remove_empty()

e_delivered_baseName <- "express_shipped_orders_"
e_delivered_files <- plants_dir |> fs::path("Express Seed export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(e_delivered_baseName,".*\\.xlsx"))
e_delivered <- foreach::foreach(i=order_files(e_delivered_files, baseName = e_delivered_baseName, parseFun = ymd), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order #", "Purchase Order #", "Customer PO #", "Order Date", "Product #", "Supplier", "QTY Ordered")), .packages = c("readxl")) %dopar% { 
  read_xlsx(e_delivered_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`))
  } |> janitor::remove_empty()

b_baseName <- "order_download_"
b_files <- plants_dir |> fs::path("Ball export") |> fs::dir_ls() |> fs::path_filter(regex = paste0(b_baseName,".*\\.xlsx"))
b_orders <- foreach::foreach(i=order_files(b_files, baseName = b_baseName, parseFun = ymd_hms), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("Order Number", "Order Line")), .packages = c("readxl","stringr")) %dopar% { 
  read_xlsx(b_files[i], guess_max = as.integer(.Machine$integer.max/100)) |>
    dplyr::mutate(vendor = "Ball",
                 "Order Number" = `Order Number` |> as.character(),
                 "Sales Order Date" = `Sales Order Date` |> lubridate::ymd(),
                 "Ship Date" = `Ship Date` |> lubridate::ymd(),
                 "Total Extended Value" = `Total Extended Value` |> as.numeric(),
                 "Order Line" = `Order Line` |> stringr::str_extract("[:digit:]*"),
                 "Ship Week" = `Ship Week` |> stringr::str_extract("[:digit:]*[:graph:]?[:digit:]*"),
                 "Case Count" = `Case Count` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Unit Price" = `Unit Price` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Royalty" = `Royalty` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Tags" = `Tags` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Freight" = `Freight` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Total Unit Rate" = `Total Unit Rate` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 # "Material Format" = string_alignment_alike(`Size`,`Material Group Description`), ##TODO
                 ) |> 
    dplyr::select(!any_of(c("Not Used1","Not Used2"))) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(`Order Number`))
  } |> janitor::remove_empty() |>
  unite(col = "Description", any_of(c("Class","Variety")), sep = " ", remove = FALSE)




mtag_baseName <- "GREENSTREET_GROWERS_INC_Order Export_"
mtag_files <- tags_dir |> fs::path("MasterTag") |> fs::dir_ls() |> fs::path_filter(regex = paste0(mtag_baseName,".*\\.xlsx"))
# registerDoParallel(cores=n_cores-1)
mtag_orders <- foreach::foreach(i=order_files(mtag_files, baseName = mtag_baseName, parseFun = mdy), .combine = \(x,y) dplyr::rows_upsert(x,y,by = c("MT Sales Order #", "MT ID")), .packages = c("foreach")) %dopar% { 
  foreach(j=c(2,1), .combine = dplyr::left_join) %dopar% {
    read_xlsx_flex(path = mtag_files[i], sheet = j, guess_max = as.integer(.Machine$integer.max/100))
  } |> janitor::remove_empty("rows") |>
    dplyr::distinct()
  } |> janitor::remove_empty() |>
    dplyr::mutate(vendor = "MasterTag",
                  "Estimated Ship Date" = `Estimated Ship Date` |> mdy() ) #,
                  # "MT Item Description" = `MT Item Description` |> str_remove_all("[:punct:]|®|™") |> str_squish() |> str_to_lower())


```

```{r singlefileimport, eval=FALSE}

e_orders <- tibble()

e_orders_file <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders/2024/Pansy&Kale 2024" |> fs::path_home() |> fs::path("express_shipped_orders_fall_2023.xlsx")

e_delivered <- read_xlsx_flex(e_orders_file, guess_max = as.integer(.Machine$integer.max/100)) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
   dplyr::filter(!is.na(`Order #`)) |> 
  janitor::remove_empty()


b_file <- "Greenstreet Growers/TeamSite - Documents/Shared/Production Greenstreet/Production Planning QC/Plant Sales and Orders/2024/Pansy&Kale 2024" |> fs::path_home() |> fs::path("Ball order_download_20240624075842.xlsx")

b_orders <- read_xlsx_flex(b_file, guess_max = as.integer(.Machine$integer.max/100)) |>
    dplyr::mutate(vendor = "Ball",
                 "Order Number" = `Order Number` |> as.character(),
                 "Sales Order Date" = `Sales Order Date` |> lubridate::ymd(),
                 "Ship Date" = `Ship Date` |> lubridate::ymd(),
                 "Total Extended Value" = `Total Extended Value` |> as.numeric(),
                 "Order Line" = `Order Line` |> stringr::str_extract("[:digit:]*"),
                 "Ship Week" = `Ship Week` |> stringr::str_extract("[:digit:]*[:graph:]?[:digit:]*"),
                 "Case Count" = `Case Count` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Unit Price" = `Unit Price` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Royalty" = `Royalty` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Tags" = `Tags` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Freight" = `Freight` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*"),
                 "Total Unit Rate" = `Total Unit Rate` |> stringr::str_extract("[:digit:]*[:punct:]?[:digit:]*")) |> 
    dplyr::select(!any_of(c("Not Used1","Not Used2"))) |>
    janitor::remove_empty("rows") |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(`Order Number`)) |> 
  janitor::remove_empty() |>
  unite(col = "Description", any_of(c("Class","Variety")), sep = " ", remove = FALSE)


## special filters
start_date <- "08-01-2023" |> mdy() |> as.POSIXct() |> as_date() |> is.Date()
end_date <- "10-31-2023" |> mdy()

e_delivered <- e_delivered |>
  mutate(across(where(is.POSIXct),as_date)) |>
  filter(`Ship Date` >= start_date,
         `Ship Date` <= end_date)

b_orders <- b_orders |> 
  mutate(across(where(is.Date),as_date)) |>
  filter(`Ship Date` >= start_date,
         `Ship Date` <= end_date)


```

```{r import_odbc, eval=FALSE}

odbc::odbcListDataSources() |> tail(1) |> select(1) |> unlist()

odbc::odbcListDrivers()

con <- DBI::dbConnect(drv = odbc::odbc(), dsn = odbc::odbcListDataSources() |> tail(1) |> select(1) |> unlist())



```


```{r e_b_join}

#skip this for single-file imports
e_combined <- e_delivered |>
# e_combined <- dplyr::full_join(e_orders, e_delivered) |>
#   select("Order #", "Customer PO #", "Order Date", "Ship Date", "Week", "Product #", "Description", "Supplier", "QTY Ordered", "Total") |>
  mutate(vendor = "Express")


alignment <- c("vendor" = "vendor", 
               "Order #" = "Order Number",
               "Customer PO #" = "PO Number", 
               "Order Date" = "Sales Order Date", 
               "Ship Date" = "Ship Date", 
               "Week" = "Ship Week", 
               "Product #" = "Ball Material Number", 
               "Description" = "Description", 
               "Supplier" = "Supplier", 
               "QTY Ordered" = "Quantity", 
               "Total" = "Total Extended Value")

b_keep_cols <- alignment |> unname() |> c("Reference Number") |> unique()

plants_joined <- full_join(e_combined, b_orders, by=alignment) %>%
  select(names(alignment)) ## |>
  # rowwise() |>
  # mutate(Description = Description |> str_to_lower() |> str_extract_all("([:alpha:]{2,})|([:digit:]*(\\.[:digit:]+)(?!C$))", simplify = TRUE) |> str_squish() |> unique() |> as.character() |> str_flatten(collapse = " "))

```

```{r filter, eval=FALSE}

if(!exists("dCluster")) {
  dCluster <- new_cluster(n_cores-1)
  cluster_library_quiety <- purrr::quietly(cluster_library)
  cluster_library_quiety(dCluster, installed_req_pkgs)
}

plants_filtered <- plants_joined |>
  partition(dCluster) |>
  dplyr::filter((`Ship Date` >= "20240101" |> ymd())&(`Ship Date` < "20240801" |> ymd()),
                Supplier |> str_equal("Kube Pak"),
                (Description |> str_detect("(^|[:space:])(HE)|(VF)[:space:]"))|(`Customer PO #` |> str_to_lower() |> str_detect("(herb)|(veg)"))) |>
  # dplyr::mutate(Description = Description |> str_remove_all("(?<=([:space:]|^))((herb)|(he)|(vf))(?=([:space:]|$))") |> str_squish()) |>
  collect()



tags_filtered <- mtag_orders |>
  dplyr::filter((`Estimated Ship Date` >= "20240101" |> ymd())&(`Estimated Ship Date` < "20240701" |> ymd()),
                str_detect(`PO #` |> str_to_lower(),"(herb)|(veg)|(daniel)"))

```

```{r mtag_join, eval = FALSE}


plants_prep <- plants_filtered |>
  summarise(`QTY Ordered` = sum(`QTY Ordered`), .by = any_of(c("Description"))) |>
  rename_with(\(x) paste0("plants_",x))

tags_prep <- tags_filtered |>
  summarise(`Ordered Quantity` = sum(`Ordered Quantity`), .by = any_of(c("MT Item Description"))) |>
  rename_with(\(x) paste0("tags_",x))

aligned <- fuzzyjoin::fuzzy_full_join(plants_prep, tags_prep, by=c("plants_Description"="tags_MT Item Description"), match_fun = name_match)
## adding tag counts
aligned %<>%
  mutate(subdept = case_when(plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(he(rb)?)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(vf)(?=($|[:space:]))") ~ "veg",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(lavandula)|(lavender)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(eucalyptus)|(lemon[:space:]?bush)(?=($|[:space:]))") ~ "herb",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(marigold)(?=($|[:space:]))") ~ "veg",
                             plants_Description |> str_to_lower() |> str_detect("(?<=(^|[:space:]))(melampodium)(?=($|[:space:]))") ~ "veg",
                             .default = NA),
         tags_per_plug = case_match(subdept,
                                    c("herb") ~ 1,
                                    c("veg") ~ 4,
                                    .default = 1),
         tags_need = `plants_QTY Ordered` / tags_per_plug,
         tags_deficit = (tags_need - datawizard::convert_na_to(`tags_Ordered Quantity`,replacement = 0)) |> pmax(0))

# can i use dplyr::join with dplyr::closest() with pairwiseAligment scores? or maybe need to use fuzzyjoin


```


```{r export, eval=FALSE}
joined %<>%
  mutate(size = case_when(str_detect(`Customer PO #`,"(^4.5)|(4.5[:space:]?((IN)|(in)|(\")))") ~ "4.5 in",
                           str_detect(`Customer PO #`,"^804") ~ "804",
                           str_detect(`Customer PO #`,"(^10)|(10[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "10 in hb",
                           str_detect(`Customer PO #`,"(^8)|(8[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "8 in hb",
                           str_detect(`Customer PO #`,"(^12)|(12[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "12 in hb",
                           str_detect(`Customer PO #`,"(^11)|(11[:space:]?((IN)|(in)|(\"))).*((HB)|(BSKT)|(BASKET))")  ~ "11 in hb",
                           str_detect(`Customer PO #`,"(^14)|(14[:space:]?((IN)|(in)|(\")))")  ~ "14 in",
                           str_detect(`Customer PO #`,"(^4)|(4[:space:]?((IN)|(in)|(\")))")  ~ "4 in",
                           str_detect(`Customer PO #`,"(^6)|(6[:space:]?((IN)|(in)|(\")))")  ~ "6 in",
                           str_detect(`Customer PO #`,"(^12)|(12[:space:]?((IN)|(in)|(\")))")  ~ "12 in",
                           str_detect(`Customer PO #`,"(^11)|(11[:space:]?((IN)|(in)|(\")))")  ~ "11 in",
                           str_detect(`Customer PO #`,"(^10)|(10[:space:]?((IN)|(in)|(\")))")  ~ "10 in",
                           str_detect(`Customer PO #`,"1[:space:]?((GAL)|(G[:space:])|(G$))")  ~ "1 gal",
                           str_detect(`Customer PO #`,"((HB)|(BSKT)|(BASKET))")  ~ "10 in hb",
                           str_detect(`Customer PO #`,"^(liner)|(LINER)")  ~ "liner",
                           str_detect(`Customer PO #`,"^PW")  ~ "PW",
                           .default = "other"))


write_xlsx_flex(joined, path = dir_path |> fs::path("2024", "ball express 2024", "spring2024_ball&express_v5.xlsx"))
```

```{r averages, eval=FALSE}

plugs_tbl <- tibble_row(size = "4 in", plugs = 1) |> # .25
  tibble::add_case(size = "4.5 in", plugs = 1)|> # .07
  tibble::add_case(size = "6 in", plugs = 3)|> # .124
  tibble::add_case(size = "10 in hb", plugs = 5)|> # .079
  tibble::add_case(size = "11 in hb", plugs = 6)|> # .069
  tibble::add_case(size = "8 in hb", plugs = 4)|> # .09
  tibble::add_case(size = "14 in", plugs = 3)|>
  tibble::add_case(size = "1 gal", plugs = 1)|>
  tibble::add_case(size = "liner", plugs = 1)|>
  tibble::add_case(size = "PW", plugs = 1)|>
  tibble::add_case(size = "12 in hb", plugs = 7)|>
  tibble::add_case(size = "12 in", plugs = 7)|>
  tibble::add_case(size = "10 in", plugs = 5)|>
  tibble::add_case(size = "804", plugs = 1)

averages <- joined |>
  dplyr::filter(`Ship Date` >= ymd("2024-01-01")) |>
  dplyr::mutate(category = if_else(str_detect(Supplier |> str_to_lower(), "four[:space:]?star"), "PW", "") |> str_c(size, sep = " ")) |>
  dplyr::summarise(dplyr::across(c("QTY Ordered","Total"),sum), .by = dplyr::any_of(c("category", "size"))) |>
  dplyr::left_join(plugs_tbl) |>
  dplyr::mutate(plug_avg_cost = Total / `QTY Ordered`,
                pot_avg_cost = plug_avg_cost * plugs) |>
  dplyr::filter(!is.na(pot_avg_cost)) |>
  select(1,3,4,6,7) |>
  dplyr::arrange(category,desc(`QTY Ordered`))

```


```{r terminateClusters, eval=FALSE}
# dplyr cluster
if(exists("dCluster")) rm(dCluster)

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
```